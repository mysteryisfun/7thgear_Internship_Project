{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b522b6bc",
   "metadata": {},
   "source": [
    "# Custom CNN v/s EfficientNet Classifier Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "060e9c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "129/129 [==============================] - 2s 15ms/step - loss: 0.2487 - accuracy: 0.9825\n",
      "129/129 [==============================] - 2s 13ms/step\n",
      "[Custom CNN] Loss: 0.2487, Accuracy: 0.9825, Precision: 0.9830, Time: 4.38s, Size: 78.06MB\n",
      "Found 1027 images belonging to 2 classes.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 6s 31ms/step - loss: 0.0939 - accuracy: 0.9864\n",
      "129/129 [==============================] - 5s 28ms/step\n",
      "[EfficientNet Functional] Loss: 0.0939, Accuracy: 0.9864, Precision: 0.9867, Time: 13.90s, Size: 23.01MB\n",
      "\n",
      "--- Model Comparison ---\n",
      "Model                         Loss   Accuracy  Precision    Time(s)   Size(MB)\n",
      "Custom CNN                0.2487     0.9825     0.9830       4.38      78.06\n",
      "EfficientNet Functional   0.0939     0.9864     0.9867      13.90      23.01\n",
      "\n",
      "Accuracy diff: +0.40%\n",
      "Precision diff: +0.37%\n",
      "Time diff: +217.04%\n",
      "Size diff: -70.52%\n"
     ]
    }
   ],
   "source": [
    "# --- TEST & COMPARE: Custom CNN vs EfficientNet Functional Model on Validation Set ---\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Paths to models\n",
    "CNN_H5_PATH = os.path.join('C:', os.sep, 'Users', 'ujwal', 'OneDrive', 'Documents', 'GitHub',\n",
    "    '7thgear_Internship_Project', 'src', 'image_processing', 'classifier1_models', 'custom_cnn_classifier_model.h5')\n",
    "FUNC_H5_PATH = os.path.join('C:', os.sep, 'Users', 'ujwal', 'OneDrive', 'Documents', 'GitHub',\n",
    "    '7thgear_Internship_Project', 'src', 'image_processing', 'classifier1_models', 'efficientnet_functional_model.h5')\n",
    "\n",
    "# Data and config\n",
    "DATA_DIR = os.path.join('C:', os.sep, 'Users', 'ujwal', 'OneDrive', 'Documents', 'GitHub',\n",
    "    '7thgear_Internship_Project', 'data', 'classifier1', 'augmented')\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# --- Custom CNN: Use rescale preprocessing ---\n",
    "datagen_cnn = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "val_gen_cnn = datagen_cnn.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "start_cnn = time.time()\n",
    "model_cnn = tf.keras.models.load_model(CNN_H5_PATH)\n",
    "cnn_results = model_cnn.evaluate(val_gen_cnn, verbose=1, return_dict=True)\n",
    "cnn_pred_probs = model_cnn.predict(val_gen_cnn)\n",
    "cnn_pred = np.argmax(cnn_pred_probs, axis=1)\n",
    "cnn_true = val_gen_cnn.classes\n",
    "cnn_acc = accuracy_score(cnn_true, cnn_pred)\n",
    "cnn_prec = precision_score(cnn_true, cnn_pred, average='weighted')\n",
    "end_cnn = time.time()\n",
    "cnn_time = end_cnn - start_cnn\n",
    "cnn_size = os.path.getsize(CNN_H5_PATH) / 1024 / 1024  # MB\n",
    "\n",
    "print(f\"[Custom CNN] Loss: {cnn_results['loss']:.4f}, Accuracy: {cnn_acc:.4f}, Precision: {cnn_prec:.4f}, Time: {cnn_time:.2f}s, Size: {cnn_size:.2f}MB\")\n",
    "\n",
    "# --- EfficientNet Functional: Use EfficientNet preprocessing ---\n",
    "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n",
    "\n",
    "datagen_func = ImageDataGenerator(preprocessing_function=preprocess_input, validation_split=0.2)\n",
    "val_gen_func = datagen_func.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "start_func = time.time()\n",
    "model_func = tf.keras.models.load_model(FUNC_H5_PATH)\n",
    "model_func.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "func_results = model_func.evaluate(val_gen_func, verbose=1, return_dict=True)\n",
    "func_pred_probs = model_func.predict(val_gen_func)\n",
    "func_pred = np.argmax(func_pred_probs, axis=1)\n",
    "func_true = val_gen_func.classes\n",
    "func_acc = accuracy_score(func_true, func_pred)\n",
    "func_prec = precision_score(func_true, func_pred, average='weighted')\n",
    "end_func = time.time()\n",
    "func_time = end_func - start_func\n",
    "func_size = os.path.getsize(FUNC_H5_PATH) / 1024 / 1024  # MB\n",
    "\n",
    "print(f\"[EfficientNet Functional] Loss: {func_results['loss']:.4f}, Accuracy: {func_acc:.4f}, Precision: {func_prec:.4f}, Time: {func_time:.2f}s, Size: {func_size:.2f}MB\")\n",
    "\n",
    "# --- Comparison Table ---\n",
    "print(\"\\n--- Model Comparison ---\")\n",
    "print(f\"{'Model':<25} {'Loss':>8} {'Accuracy':>10} {'Precision':>10} {'Time(s)':>10} {'Size(MB)':>10}\")\n",
    "print(f\"{'Custom CNN':<25} {cnn_results['loss']:.4f} {cnn_acc:10.4f} {cnn_prec:10.4f} {cnn_time:10.2f} {cnn_size:10.2f}\")\n",
    "print(f\"{'EfficientNet Functional':<25} {func_results['loss']:.4f} {func_acc:10.4f} {func_prec:10.4f} {func_time:10.2f} {func_size:10.2f}\")\n",
    "\n",
    "# Percentage differences\n",
    "acc_diff = 100 * (func_acc - cnn_acc) / cnn_acc if cnn_acc else 0\n",
    "prec_diff = 100 * (func_prec - cnn_prec) / cnn_prec if cnn_prec else 0\n",
    "time_diff = 100 * (func_time - cnn_time) / cnn_time if cnn_time else 0\n",
    "size_diff = 100 * (func_size - cnn_size) / cnn_size if cnn_size else 0\n",
    "print(f\"\\nAccuracy diff: {acc_diff:+.2f}%\\nPrecision diff: {prec_diff:+.2f}%\\nTime diff: {time_diff:+.2f}%\\nSize diff: {size_diff:+.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
